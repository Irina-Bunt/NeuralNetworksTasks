{"cells":[{"cell_type":"markdown","metadata":{"id":"vuQKRYkhCvU2"},"source":["# Задание 6: Рекуррентные нейронные сети (RNNs)\n","\n","Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"P59NYU98GCb9","executionInfo":{"status":"ok","timestamp":1682354201363,"user_tz":-420,"elapsed":17016,"user":{"displayName":"Machine","userId":"11630897638309145340"}}},"outputs":[],"source":["!pip3 -qq install torch\n","!pip3 -qq install bokeh==0.13.0\n","!pip3 -qq install gensim==3.6.0\n","!pip3 -qq install nltk\n","!pip3 -qq install scikit-learn"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8sVtGHmA9aBM","executionInfo":{"status":"ok","timestamp":1682359007532,"user_tz":-420,"elapsed":1582,"user":{"displayName":"Machine","userId":"11630897638309145340"}}},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","\n","if torch.cuda.is_available():\n","    from torch.cuda import FloatTensor, LongTensor\n","else:\n","    from torch import FloatTensor, LongTensor\n","\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{"id":"-6CNKM3b4hT1"},"source":["# Рекуррентные нейронные сети (RNNs)"]},{"cell_type":"markdown","metadata":{"id":"O_XkoGNQUeGm"},"source":["## POS Tagging"]},{"cell_type":"markdown","metadata":{"id":"QFEtWrS_4rUs"},"source":["Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n","\n","![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n","\n","*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n","\n","Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n","\n","Мы порешаем сейчас POS Tagging для английского.\n","\n","Будем работать с таким набором тегов:\n","- ADJ - adjective (new, good, high, ...)\n","- ADP - adposition (on, of, at, ...)\n","- ADV - adverb (really, already, still, ...)\n","- CONJ - conjunction (and, or, but, ...)\n","- DET - determiner, article (the, a, some, ...)\n","- NOUN - noun (year, home, costs, ...)\n","- NUM - numeral (twenty-four, fourth, 1991, ...)\n","- PRT - particle (at, on, out, ...)\n","- PRON - pronoun (he, their, her, ...)\n","- VERB - verb (is, say, told, ...)\n","- . - punctuation marks (. , ;)\n","- X - other (ersatz, esprit, dunno, ...)"]},{"cell_type":"markdown","metadata":{"id":"EPIkKdFlHB-X"},"source":["Скачаем данные:"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TiA2dGmgF1rW","executionInfo":{"status":"ok","timestamp":1682359012667,"user_tz":-420,"elapsed":1181,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"bf17c459-65eb-481c-bf0b-1a72d4cc6ca8"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Package universal_tagset is already up-to-date!\n"]}],"source":["import nltk\n","from sklearn.model_selection import train_test_split\n","\n","nltk.download('brown')\n","nltk.download('universal_tagset')\n","\n","data = nltk.corpus.brown.tagged_sents(tagset='universal')"]},{"cell_type":"markdown","metadata":{"id":"d93g_swyJA_V"},"source":["Пример размеченного предложения:"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QstS4NO0L97c","executionInfo":{"status":"ok","timestamp":1682359015016,"user_tz":-420,"elapsed":701,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"69e07c10-8410-4e14-d0b4-d115c1d26fc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["The            \tDET\n","Fulton         \tNOUN\n","County         \tNOUN\n","Grand          \tADJ\n","Jury           \tNOUN\n","said           \tVERB\n","Friday         \tNOUN\n","an             \tDET\n","investigation  \tNOUN\n","of             \tADP\n","Atlanta's      \tNOUN\n","recent         \tADJ\n","primary        \tNOUN\n","election       \tNOUN\n","produced       \tVERB\n","``             \t.\n","no             \tDET\n","evidence       \tNOUN\n","''             \t.\n","that           \tADP\n","any            \tDET\n","irregularities \tNOUN\n","took           \tVERB\n","place          \tNOUN\n",".              \t.\n"]}],"source":["for word, tag in data[0]:\n","    print('{:15}\\t{}'.format(word, tag))"]},{"cell_type":"markdown","metadata":{"id":"epdW8u_YXcAv"},"source":["Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n","\n","На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTai8Ta0lgwL","executionInfo":{"status":"ok","timestamp":1682359041373,"user_tz":-420,"elapsed":23865,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"cc2b9f7e-76f0-46e1-857b-dd3a8d05ad49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Words count in train set: 739769\n","Words count in val set: 130954\n","Words count in test set: 290469\n"]}],"source":["train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n","train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n","\n","print('Words count in train set:', sum(len(sent) for sent in train_data))\n","print('Words count in val set:', sum(len(sent) for sent in val_data))\n","print('Words count in test set:', sum(len(sent) for sent in test_data))"]},{"cell_type":"markdown","metadata":{"id":"eChdLNGtXyP0"},"source":["Построим маппинги из слов в индекс и из тега в индекс:\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCjwwDs6Zq9x","executionInfo":{"status":"ok","timestamp":1682359045962,"user_tz":-420,"elapsed":793,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"164e5ad3-8a94-4953-e78a-7e3f67b8a50d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique words in train = 45441. Tags = {'X', 'ADV', '.', 'NUM', 'DET', 'CONJ', 'NOUN', 'ADP', 'PRT', 'ADJ', 'VERB', 'PRON'}\n"]}],"source":["words = {word for sample in train_data for word, tag in sample}\n","word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n","word2ind['<pad>'] = 0\n","\n","tags = {tag for sample in train_data for word, tag in sample}\n","tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n","tag2ind['<pad>'] = 0\n","\n","print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"id":"URC1B2nvPGFt","executionInfo":{"status":"ok","timestamp":1682359049450,"user_tz":-420,"elapsed":414,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"58fcb148-dad4-46cf-8248-2d75844f3fa6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from collections import Counter\n","\n","tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n","tag_distribution = [tag_distribution[tag] for tag in tags]\n","\n","plt.figure(figsize=(10, 5))\n","\n","bar_width = 0.35\n","plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n","plt.xticks(np.arange(len(tags)), tags)\n","    \n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gArQwbzWWkgi"},"source":["## Бейзлайн\n","\n","Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n","\n","![tag-context](https://www.nltk.org/images/tag-context.png)  \n","*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n","\n","На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n","\n","Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n","\n","Простейший вариант - униграммная модель, учитывающая только слово:"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rWmSToIaeAo","executionInfo":{"status":"ok","timestamp":1682359055517,"user_tz":-420,"elapsed":2279,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"5769eace-f61f-4940-db88-a52f1daeb9ef"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-747c80ba0bc0>:6: DeprecationWarning: \n","  Function evaluate() has been deprecated.  Use accuracy(gold)\n","  instead.\n","  print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy of unigram tagger = 92.62%\n"]}],"source":["import nltk\n","\n","default_tagger = nltk.DefaultTagger('NN')\n","\n","unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n","print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"]},{"cell_type":"markdown","metadata":{"id":"07Ymb_MkbWsF"},"source":["Добавим вероятности переходов:"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjz_Rk0bbMyH","executionInfo":{"status":"ok","timestamp":1682359063071,"user_tz":-420,"elapsed":4818,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"7cdeebe0-9e40-4c04-c36a-7b49c8438718"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-0f47def21c45>:2: DeprecationWarning: \n","  Function evaluate() has been deprecated.  Use accuracy(gold)\n","  instead.\n","  print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy of bigram tagger = 93.42%\n"]}],"source":["bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n","print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"]},{"cell_type":"markdown","metadata":{"id":"uWMw6QHvbaDd"},"source":["Обратите внимание, что `backoff` важен:"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XCuxEBVbOY_","executionInfo":{"status":"ok","timestamp":1682359069404,"user_tz":-420,"elapsed":4183,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"41cc2f7a-412a-453f-c6d3-e36b5b52230c"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-89f0185880b7>:2: DeprecationWarning: \n","  Function evaluate() has been deprecated.  Use accuracy(gold)\n","  instead.\n","  print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy of trigram tagger = 23.33%\n"]}],"source":["trigram_tagger = nltk.TrigramTagger(train_data)\n","print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"]},{"cell_type":"markdown","metadata":{"id":"4t3xyYd__8d-"},"source":["## Увеличиваем контекст с рекуррентными сетями\n","\n","Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n","\n","Омонимия - основная причина, почему униграмная модель плоха:  \n","*“he cashed a check at the **bank**”*  \n","vs  \n","*“he sat on the **bank** of the river”*\n","\n","Поэтому нам очень полезно учитывать контекст при предсказании тега.\n","\n","Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n","\n","![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n","\n","Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"RtRbz1SwgEqc","executionInfo":{"status":"ok","timestamp":1682359075102,"user_tz":-420,"elapsed":1553,"user":{"displayName":"Machine","userId":"11630897638309145340"}}},"outputs":[],"source":["def convert_data(data, word2ind, tag2ind):\n","    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n","    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n","    \n","    return X, y\n","\n","X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n","X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n","X_test, y_test = convert_data(test_data, word2ind, tag2ind)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"DhsTKZalfih6","executionInfo":{"status":"ok","timestamp":1682359077485,"user_tz":-420,"elapsed":287,"user":{"displayName":"Machine","userId":"11630897638309145340"}}},"outputs":[],"source":["def iterate_batches(data, batch_size):\n","    X, y = data\n","    n_samples = len(X)\n","\n","    indices = np.arange(n_samples)\n","    np.random.shuffle(indices)\n","    \n","    for start in range(0, n_samples, batch_size):\n","        end = min(start + batch_size, n_samples)\n","        \n","        batch_indices = indices[start:end]\n","        \n","        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n","        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n","        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n","        \n","        for batch_ind, sample_ind in enumerate(batch_indices):\n","            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n","            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n","            \n","        yield X_batch, y_batch"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4XsRII5kW5x","executionInfo":{"status":"ok","timestamp":1682359079837,"user_tz":-420,"elapsed":275,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"ae75e9c3-196b-4f3a-d70a-f300e1fcee57"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((32, 4), (32, 4))"]},"metadata":{},"execution_count":14}],"source":["X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n","\n","X_batch.shape, y_batch.shape"]},{"cell_type":"markdown","metadata":{"id":"C5I9E9P6eFYv"},"source":["**Задание** Реализуйте `LSTMTagger`:"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"WVEHju54d68T","executionInfo":{"status":"ok","timestamp":1682359083153,"user_tz":-420,"elapsed":934,"user":{"displayName":"Machine","userId":"11630897638309145340"}}},"outputs":[],"source":["class LSTMTagger(nn.Module):\n","    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n","        self.lstm_layer = torch.nn.LSTM(input_size=word_emb_dim, hidden_size=lstm_hidden_dim, num_layers=lstm_layers_count\n","                          )\n","        self.FC = nn.Linear(lstm_hidden_dim, tagset_size)\n","        # self.h0 = torch.randn(2, 3, 20)\n","        # self.c0 = torch.randn(2, 3, 20)\n","\n","    def forward(self, inputs):\n","        embedding  = self.embedding(inputs)\n","        output, _ = self.lstm_layer(embedding)\n","        output = self.FC(output)\n","        return output"]},{"cell_type":"code","source":["X_batch[:,:, None].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mve85b3sO7ow","executionInfo":{"status":"ok","timestamp":1682356399289,"user_tz":-420,"elapsed":334,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"3c7a4e50-6dd5-4508-f6be-438b5d56ecaa"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 4, 1])"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"q_HA8zyheYGH"},"source":["**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"jbrxsZ2mehWB","executionInfo":{"status":"ok","timestamp":1682359087551,"user_tz":-420,"elapsed":288,"user":{"displayName":"Machine","userId":"11630897638309145340"}}},"outputs":[],"source":["model = LSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",")\n","\n","X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n","\n","logits = model(X_batch)\n","\n","def get_accuracy(prediction, ground_truth):\n","    _, indices = torch.max(prediction, -1)\n","    total = torch.sum(ground_truth>0).item()\n","    corr = torch.sum((indices == ground_truth)*(ground_truth>0)).item()\n","    return corr, total\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMUyUm1hgpe3","executionInfo":{"status":"ok","timestamp":1682359089782,"user_tz":-420,"elapsed":387,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"271242f9-7287-4bc7-e235-dd843cb5caed"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.5516, grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":17}],"source":["criterion = nn.CrossEntropyLoss()\n","criterion(logits.reshape((-1,len(tag2ind))), y_batch.view(-1))"]},{"cell_type":"markdown","metadata":{"id":"nSgV3NPUpcjH"},"source":["**Задание** Вставьте эти вычисление в функцию:"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"FprPQ0gllo7b","executionInfo":{"status":"ok","timestamp":1682359092336,"user_tz":-420,"elapsed":282,"user":{"displayName":"Machine","userId":"11630897638309145340"}}},"outputs":[],"source":["import math\n","from tqdm import tqdm\n","\n","\n","def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n","    epoch_loss = 0\n","    correct_count = 0\n","    sum_count = 0\n","    loss_function = nn.CrossEntropyLoss()\n","    is_train = not optimizer is None\n","    name = name or ''\n","    model.train(is_train)\n","    \n","    batches_count = math.ceil(len(data[0]) / batch_size)\n","    \n","    with torch.autograd.set_grad_enabled(is_train):\n","        with tqdm(total=batches_count) as progress_bar:\n","            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n","                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n","                logits = model(X_batch)\n","\n","                loss = loss_function(logits.reshape((-1,len(tag2ind))), y_batch.view(-1))\n","\n","                epoch_loss += loss.item()\n","\n","                if optimizer:\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","\n","                cur_correct_count, cur_sum_count = get_accuracy(logits, y_batch)\n","\n","                correct_count += cur_correct_count\n","                sum_count += cur_sum_count\n","\n","                progress_bar.update()\n","                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n","                    name, loss.item(), cur_correct_count / cur_sum_count)\n","                )\n","                \n","            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n","                name, epoch_loss / batches_count, correct_count / sum_count)\n","            )\n","\n","    return epoch_loss / batches_count, correct_count / sum_count\n","\n","\n","def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n","        val_data=None, val_batch_size=None):\n","        \n","    if not val_data is None and val_batch_size is None:\n","        val_batch_size = batch_size\n","        \n","    for epoch in range(epochs_count):\n","        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n","        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n","        \n","        if not val_data is None:\n","            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pqfbeh1ltEYa","executionInfo":{"status":"ok","timestamp":1682359224598,"user_tz":-420,"elapsed":96459,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"6083fdb9-7af0-4723-8a41-a0d87ce798d5"},"outputs":[{"output_type":"stream","name":"stderr","text":["[1 / 20] Train: Loss = 0.31906, Accuracy = 71.13%: 100%|██████████| 572/572 [00:04<00:00, 124.93it/s]\n","[1 / 20]   Val: Loss = 0.10158, Accuracy = 85.43%: 100%|██████████| 13/13 [00:00<00:00, 70.98it/s]\n","[2 / 20] Train: Loss = 0.10081, Accuracy = 89.97%: 100%|██████████| 572/572 [00:04<00:00, 127.73it/s]\n","[2 / 20]   Val: Loss = 0.07910, Accuracy = 89.59%: 100%|██████████| 13/13 [00:00<00:00, 74.11it/s]\n","[3 / 20] Train: Loss = 0.06769, Accuracy = 93.25%: 100%|██████████| 572/572 [00:04<00:00, 118.46it/s]\n","[3 / 20]   Val: Loss = 0.06592, Accuracy = 90.91%: 100%|██████████| 13/13 [00:00<00:00, 73.81it/s]\n","[4 / 20] Train: Loss = 0.05133, Accuracy = 94.84%: 100%|██████████| 572/572 [00:04<00:00, 128.69it/s]\n","[4 / 20]   Val: Loss = 0.07175, Accuracy = 91.90%: 100%|██████████| 13/13 [00:00<00:00, 75.10it/s]\n","[5 / 20] Train: Loss = 0.04045, Accuracy = 95.87%: 100%|██████████| 572/572 [00:04<00:00, 127.77it/s]\n","[5 / 20]   Val: Loss = 0.06408, Accuracy = 92.44%: 100%|██████████| 13/13 [00:00<00:00, 73.07it/s]\n","[6 / 20] Train: Loss = 0.03310, Accuracy = 96.61%: 100%|██████████| 572/572 [00:04<00:00, 116.59it/s]\n","[6 / 20]   Val: Loss = 0.06472, Accuracy = 92.85%: 100%|██████████| 13/13 [00:00<00:00, 76.16it/s]\n","[7 / 20] Train: Loss = 0.02737, Accuracy = 97.17%: 100%|██████████| 572/572 [00:04<00:00, 126.67it/s]\n","[7 / 20]   Val: Loss = 0.06541, Accuracy = 92.95%: 100%|██████████| 13/13 [00:00<00:00, 74.01it/s]\n","[8 / 20] Train: Loss = 0.02267, Accuracy = 97.65%: 100%|██████████| 572/572 [00:04<00:00, 125.32it/s]\n","[8 / 20]   Val: Loss = 0.07334, Accuracy = 93.09%: 100%|██████████| 13/13 [00:00<00:00, 60.75it/s]\n","[9 / 20] Train: Loss = 0.01879, Accuracy = 98.07%: 100%|██████████| 572/572 [00:04<00:00, 118.99it/s]\n","[9 / 20]   Val: Loss = 0.06876, Accuracy = 93.03%: 100%|██████████| 13/13 [00:00<00:00, 73.63it/s]\n","[10 / 20] Train: Loss = 0.01558, Accuracy = 98.39%: 100%|██████████| 572/572 [00:04<00:00, 126.97it/s]\n","[10 / 20]   Val: Loss = 0.07440, Accuracy = 93.04%: 100%|██████████| 13/13 [00:00<00:00, 75.26it/s]\n","[11 / 20] Train: Loss = 0.01290, Accuracy = 98.69%: 100%|██████████| 572/572 [00:04<00:00, 125.94it/s]\n","[11 / 20]   Val: Loss = 0.07712, Accuracy = 92.91%: 100%|██████████| 13/13 [00:00<00:00, 64.92it/s]\n","[12 / 20] Train: Loss = 0.01062, Accuracy = 98.94%: 100%|██████████| 572/572 [00:04<00:00, 118.29it/s]\n","[12 / 20]   Val: Loss = 0.08284, Accuracy = 92.98%: 100%|██████████| 13/13 [00:00<00:00, 75.05it/s]\n","[13 / 20] Train: Loss = 0.00865, Accuracy = 99.15%: 100%|██████████| 572/572 [00:04<00:00, 126.39it/s]\n","[13 / 20]   Val: Loss = 0.08569, Accuracy = 92.92%: 100%|██████████| 13/13 [00:00<00:00, 73.85it/s]\n","[14 / 20] Train: Loss = 0.00705, Accuracy = 99.31%: 100%|██████████| 572/572 [00:04<00:00, 123.79it/s]\n","[14 / 20]   Val: Loss = 0.08896, Accuracy = 92.86%: 100%|██████████| 13/13 [00:00<00:00, 70.66it/s]\n","[15 / 20] Train: Loss = 0.00559, Accuracy = 99.47%: 100%|██████████| 572/572 [00:04<00:00, 120.00it/s]\n","[15 / 20]   Val: Loss = 0.08852, Accuracy = 92.78%: 100%|██████████| 13/13 [00:00<00:00, 71.28it/s]\n","[16 / 20] Train: Loss = 0.00468, Accuracy = 99.57%: 100%|██████████| 572/572 [00:04<00:00, 124.53it/s]\n","[16 / 20]   Val: Loss = 0.09620, Accuracy = 92.73%: 100%|██████████| 13/13 [00:00<00:00, 69.24it/s]\n","[17 / 20] Train: Loss = 0.00371, Accuracy = 99.67%: 100%|██████████| 572/572 [00:04<00:00, 124.58it/s]\n","[17 / 20]   Val: Loss = 0.10220, Accuracy = 92.79%: 100%|██████████| 13/13 [00:00<00:00, 70.66it/s]\n","[18 / 20] Train: Loss = 0.00305, Accuracy = 99.73%: 100%|██████████| 572/572 [00:04<00:00, 121.90it/s]\n","[18 / 20]   Val: Loss = 0.10600, Accuracy = 92.73%: 100%|██████████| 13/13 [00:00<00:00, 73.41it/s]\n","[19 / 20] Train: Loss = 0.00263, Accuracy = 99.76%: 100%|██████████| 572/572 [00:04<00:00, 125.72it/s]\n","[19 / 20]   Val: Loss = 0.11104, Accuracy = 92.77%: 100%|██████████| 13/13 [00:00<00:00, 75.93it/s]\n","[20 / 20] Train: Loss = 0.00239, Accuracy = 99.78%: 100%|██████████| 572/572 [00:04<00:00, 124.56it/s]\n","[20 / 20]   Val: Loss = 0.10828, Accuracy = 92.62%: 100%|██████████| 13/13 [00:00<00:00, 58.05it/s]\n"]}],"source":["model = LSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss().cuda()\n","optimizer = optim.Adam(model.parameters())\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"]},{"cell_type":"markdown","metadata":{"id":"m0qGetIhfUE5"},"source":["### Masking\n","\n","**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n","\n","У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."]},{"cell_type":"markdown","metadata":{"id":"nAfV2dEOfHo5"},"source":["**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98wr38_rw55D","executionInfo":{"status":"ok","timestamp":1682359245269,"user_tz":-420,"elapsed":645,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"39681c9b-fd64-4041-9900-1e42bc7d039c"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.928928373126041\n"]}],"source":["accum = 0\n","butch_count = 0\n","for X_test_batch, y_test_batch in iterate_batches((X_test, y_test), 512):\n","    X_batch, y_batch = LongTensor(X_test_batch), LongTensor(y_test_batch)\n","    test_prediction = model(X_batch)\n","    butch_count += 1\n","    right, all = get_accuracy(test_prediction, y_batch)\n","    accum = right / all\n","average = accum / butch_count\n","print(accum)\n","# X_test_batch, y_test_batch = next(iterate_batches((X_test, y_test), 512))"]},{"cell_type":"markdown","metadata":{"id":"PXUTSFaEHbDG"},"source":["### Bidirectional LSTM\n","\n","Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n","\n","![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n","*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n","\n","**Задание** Добавьте Bidirectional LSTM."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Qb7Gta22CvVT","executionInfo":{"status":"ok","timestamp":1682359270564,"user_tz":-420,"elapsed":287,"user":{"displayName":"Machine","userId":"11630897638309145340"}}},"outputs":[],"source":["class BidirectionalLSTMTagger(nn.Module):\n","    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n","        self.lstm_layer = torch.nn.LSTM(input_size=word_emb_dim, hidden_size=lstm_hidden_dim, num_layers=lstm_layers_count,\n","                          bidirectional=True)\n","        self.FC = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n","        # self.h0 = torch.randn(2, 3, 20)\n","        # self.c0 = torch.randn(2, 3, 20)\n","\n","    def forward(self, inputs):\n","        embedding  = self.embedding(inputs)\n","        output, _ = self.lstm_layer(embedding)\n","        output = self.FC(output)\n","        return output\n","\n"]},{"cell_type":"code","source":["model = BidirectionalLSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss().cuda()\n","optimizer = optim.Adam(model.parameters())\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=12,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjoSwcGnZptH","executionInfo":{"status":"ok","timestamp":1682359400148,"user_tz":-420,"elapsed":70328,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"55b2bf9e-3660-4f54-dacb-6ed2ccf8fd94"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["[1 / 12] Train: Loss = 0.25152, Accuracy = 76.66%: 100%|██████████| 572/572 [00:05<00:00, 101.88it/s]\n","[1 / 12]   Val: Loss = 0.07937, Accuracy = 88.99%: 100%|██████████| 13/13 [00:00<00:00, 48.53it/s]\n","[2 / 12] Train: Loss = 0.07692, Accuracy = 92.53%: 100%|██████████| 572/572 [00:05<00:00, 107.44it/s]\n","[2 / 12]   Val: Loss = 0.04862, Accuracy = 92.88%: 100%|██████████| 13/13 [00:00<00:00, 42.35it/s]\n","[3 / 12] Train: Loss = 0.04963, Accuracy = 95.28%: 100%|██████████| 572/572 [00:05<00:00, 102.14it/s]\n","[3 / 12]   Val: Loss = 0.04070, Accuracy = 94.17%: 100%|██████████| 13/13 [00:00<00:00, 47.17it/s]\n","[4 / 12] Train: Loss = 0.03538, Accuracy = 96.70%: 100%|██████████| 572/572 [00:05<00:00, 108.43it/s]\n","[4 / 12]   Val: Loss = 0.03893, Accuracy = 94.72%: 100%|██████████| 13/13 [00:00<00:00, 47.37it/s]\n","[5 / 12] Train: Loss = 0.02547, Accuracy = 97.60%: 100%|██████████| 572/572 [00:05<00:00, 101.02it/s]\n","[5 / 12]   Val: Loss = 0.03674, Accuracy = 95.02%: 100%|██████████| 13/13 [00:00<00:00, 46.14it/s]\n","[6 / 12] Train: Loss = 0.01876, Accuracy = 98.26%: 100%|██████████| 572/572 [00:05<00:00, 105.90it/s]\n","[6 / 12]   Val: Loss = 0.03463, Accuracy = 95.33%: 100%|██████████| 13/13 [00:00<00:00, 46.74it/s]\n","[7 / 12] Train: Loss = 0.01354, Accuracy = 98.80%: 100%|██████████| 572/572 [00:05<00:00, 105.88it/s]\n","[7 / 12]   Val: Loss = 0.03568, Accuracy = 95.35%: 100%|██████████| 13/13 [00:00<00:00, 42.57it/s]\n","[8 / 12] Train: Loss = 0.00960, Accuracy = 99.16%: 100%|██████████| 572/572 [00:05<00:00, 103.56it/s]\n","[8 / 12]   Val: Loss = 0.03580, Accuracy = 95.38%: 100%|██████████| 13/13 [00:00<00:00, 46.80it/s]\n","[9 / 12] Train: Loss = 0.00654, Accuracy = 99.45%: 100%|██████████| 572/572 [00:05<00:00, 105.64it/s]\n","[9 / 12]   Val: Loss = 0.03596, Accuracy = 95.55%: 100%|██████████| 13/13 [00:00<00:00, 45.36it/s]\n","[10 / 12] Train: Loss = 0.00438, Accuracy = 99.66%: 100%|██████████| 572/572 [00:05<00:00, 101.27it/s]\n","[10 / 12]   Val: Loss = 0.03867, Accuracy = 95.75%: 100%|██████████| 13/13 [00:00<00:00, 47.50it/s]\n","[11 / 12] Train: Loss = 0.00275, Accuracy = 99.82%: 100%|██████████| 572/572 [00:05<00:00, 105.75it/s]\n","[11 / 12]   Val: Loss = 0.04258, Accuracy = 95.60%: 100%|██████████| 13/13 [00:00<00:00, 46.98it/s]\n","[12 / 12] Train: Loss = 0.00181, Accuracy = 99.90%: 100%|██████████| 572/572 [00:05<00:00, 104.68it/s]\n","[12 / 12]   Val: Loss = 0.04330, Accuracy = 95.68%: 100%|██████████| 13/13 [00:00<00:00, 40.68it/s]\n"]}]},{"cell_type":"code","source":["accum = 0\n","butch_count = 0\n","for X_test_batch, y_test_batch in iterate_batches((X_test, y_test), 512):\n","    X_batch, y_batch = LongTensor(X_test_batch), LongTensor(y_test_batch)\n","    test_prediction = model(X_batch)\n","    butch_count += 1\n","    right, all = get_accuracy(test_prediction, y_batch)\n","    accum = right / all\n","average = accum / butch_count\n","print(accum)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oBeM3509Zy9f","executionInfo":{"status":"ok","timestamp":1682359412561,"user_tz":-420,"elapsed":407,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"72c46b79-2263-418b-8ab3-957e87b22ac4"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9615701627859057\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZTXmYGD_ANhm"},"source":["### Предобученные эмбеддинги\n","\n","Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n","\n","Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZpY_Q1xZ18h","executionInfo":{"status":"ok","timestamp":1682358984408,"user_tz":-420,"elapsed":57096,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"4b08dc6e-3f4c-4f45-b437-1cd0ff0c8348"},"outputs":[{"output_type":"stream","name":"stdout","text":["[=================================================-] 99.0% 126.8/128.1MB downloaded\n"]}],"source":["import gensim.downloader as api\n","\n","w2v_model = api.load('glove-wiki-gigaword-100')"]},{"cell_type":"markdown","metadata":{"id":"KYogOoKlgtcf"},"source":["Построим подматрицу для слов из нашей тренировочной выборки:"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VsCstxiO03oT","executionInfo":{"status":"ok","timestamp":1682359425435,"user_tz":-420,"elapsed":284,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"2ef5c807-baca-4a92-cf55-a716ee576d9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Know 38736 out of 45441 word embeddings\n"]}],"source":["known_count = 0\n","embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n","for word, ind in word2ind.items():\n","    word = word.lower()\n","    if word in w2v_model.vocab:\n","        embeddings[ind] = w2v_model.get_vector(word)\n","        known_count += 1\n","        \n","print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"]},{"cell_type":"code","source":["embeddings.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0lokckqcN3Z","executionInfo":{"status":"ok","timestamp":1682359524161,"user_tz":-420,"elapsed":454,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"5159357a-43ca-4971-d12f-a2a282176189"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(45441, 100)"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"HcG7i-R8hbY3"},"source":["**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."]},{"cell_type":"code","execution_count":79,"metadata":{"id":"LxaRBpQd0pat","executionInfo":{"status":"ok","timestamp":1682360394435,"user_tz":-420,"elapsed":350,"user":{"displayName":"Machine","userId":"11630897638309145340"}}},"outputs":[],"source":["class LSTMTaggerWithPretrainedEmbs(nn.Module):\n","    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n","        super().__init__()\n","        self.embeddings = torch.FloatTensor(embeddings)\n","        self.embeddings = self.embeddings.to(device='cuda')\n","        self.embeddings = nn.Embedding.from_pretrained(self.embeddings)\n","        self.lstm_layer = torch.nn.LSTM(input_size=embeddings.shape[1], hidden_size=lstm_hidden_dim, num_layers=lstm_layers_count,\n","                          bidirectional=True)\n","        self.FC = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n","\n","    def forward(self, inputs):\n","        embeddings  = self.embeddings(inputs)\n","        output, _ = self.lstm_layer(embeddings)\n","        output = self.FC(output)\n","        return output\n"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBtI6BDE-Fc7","executionInfo":{"status":"ok","timestamp":1682360473150,"user_tz":-420,"elapsed":77132,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"41a666db-e3b8-4f9d-ffa5-e02cd7838e6c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[1 / 20] Train: Loss = 0.31073, Accuracy = 78.22%: 100%|██████████| 572/572 [00:03<00:00, 162.04it/s]\n","[1 / 20]   Val: Loss = 0.06202, Accuracy = 91.31%: 100%|██████████| 13/13 [00:00<00:00, 66.11it/s]\n","[2 / 20] Train: Loss = 0.07238, Accuracy = 93.67%: 100%|██████████| 572/572 [00:03<00:00, 149.96it/s]\n","[2 / 20]   Val: Loss = 0.04319, Accuracy = 94.15%: 100%|██████████| 13/13 [00:00<00:00, 55.74it/s]\n","[3 / 20] Train: Loss = 0.04940, Accuracy = 95.53%: 100%|██████████| 572/572 [00:03<00:00, 162.75it/s]\n","[3 / 20]   Val: Loss = 0.03406, Accuracy = 95.36%: 100%|██████████| 13/13 [00:00<00:00, 70.36it/s]\n","[4 / 20] Train: Loss = 0.03893, Accuracy = 96.44%: 100%|██████████| 572/572 [00:03<00:00, 167.77it/s]\n","[4 / 20]   Val: Loss = 0.02646, Accuracy = 95.97%: 100%|██████████| 13/13 [00:00<00:00, 68.55it/s]\n","[5 / 20] Train: Loss = 0.03298, Accuracy = 96.96%: 100%|██████████| 572/572 [00:03<00:00, 165.47it/s]\n","[5 / 20]   Val: Loss = 0.02785, Accuracy = 96.30%: 100%|██████████| 13/13 [00:00<00:00, 61.62it/s]\n","[6 / 20] Train: Loss = 0.02921, Accuracy = 97.30%: 100%|██████████| 572/572 [00:03<00:00, 149.67it/s]\n","[6 / 20]   Val: Loss = 0.02367, Accuracy = 96.48%: 100%|██████████| 13/13 [00:00<00:00, 59.01it/s]\n","[7 / 20] Train: Loss = 0.02618, Accuracy = 97.55%: 100%|██████████| 572/572 [00:03<00:00, 162.85it/s]\n","[7 / 20]   Val: Loss = 0.02267, Accuracy = 96.64%: 100%|██████████| 13/13 [00:00<00:00, 69.39it/s]\n","[8 / 20] Train: Loss = 0.02402, Accuracy = 97.75%: 100%|██████████| 572/572 [00:03<00:00, 165.41it/s]\n","[8 / 20]   Val: Loss = 0.02232, Accuracy = 96.82%: 100%|██████████| 13/13 [00:00<00:00, 70.39it/s]\n","[9 / 20] Train: Loss = 0.02211, Accuracy = 97.90%: 100%|██████████| 572/572 [00:03<00:00, 157.76it/s]\n","[9 / 20]   Val: Loss = 0.02109, Accuracy = 96.89%: 100%|██████████| 13/13 [00:00<00:00, 62.68it/s]\n","[10 / 20] Train: Loss = 0.02075, Accuracy = 98.03%: 100%|██████████| 572/572 [00:03<00:00, 147.72it/s]\n","[10 / 20]   Val: Loss = 0.01958, Accuracy = 96.94%: 100%|██████████| 13/13 [00:00<00:00, 60.27it/s]\n","[11 / 20] Train: Loss = 0.01939, Accuracy = 98.15%: 100%|██████████| 572/572 [00:03<00:00, 165.61it/s]\n","[11 / 20]   Val: Loss = 0.01999, Accuracy = 96.96%: 100%|██████████| 13/13 [00:00<00:00, 68.67it/s]\n","[12 / 20] Train: Loss = 0.01818, Accuracy = 98.25%: 100%|██████████| 572/572 [00:03<00:00, 162.25it/s]\n","[12 / 20]   Val: Loss = 0.02051, Accuracy = 96.99%: 100%|██████████| 13/13 [00:00<00:00, 68.54it/s]\n","[13 / 20] Train: Loss = 0.01742, Accuracy = 98.34%: 100%|██████████| 572/572 [00:03<00:00, 157.03it/s]\n","[13 / 20]   Val: Loss = 0.01948, Accuracy = 97.02%: 100%|██████████| 13/13 [00:00<00:00, 62.88it/s]\n","[14 / 20] Train: Loss = 0.01635, Accuracy = 98.43%: 100%|██████████| 572/572 [00:03<00:00, 155.59it/s]\n","[14 / 20]   Val: Loss = 0.01894, Accuracy = 97.04%: 100%|██████████| 13/13 [00:00<00:00, 57.55it/s]\n","[15 / 20] Train: Loss = 0.01559, Accuracy = 98.51%: 100%|██████████| 572/572 [00:03<00:00, 159.05it/s]\n","[15 / 20]   Val: Loss = 0.02031, Accuracy = 97.05%: 100%|██████████| 13/13 [00:00<00:00, 67.33it/s]\n","[16 / 20] Train: Loss = 0.01471, Accuracy = 98.59%: 100%|██████████| 572/572 [00:03<00:00, 160.98it/s]\n","[16 / 20]   Val: Loss = 0.02076, Accuracy = 97.06%: 100%|██████████| 13/13 [00:00<00:00, 71.36it/s]\n","[17 / 20] Train: Loss = 0.01402, Accuracy = 98.64%: 100%|██████████| 572/572 [00:03<00:00, 155.03it/s]\n","[17 / 20]   Val: Loss = 0.02087, Accuracy = 97.08%: 100%|██████████| 13/13 [00:00<00:00, 60.53it/s]\n","[18 / 20] Train: Loss = 0.01351, Accuracy = 98.72%: 100%|██████████| 572/572 [00:03<00:00, 152.00it/s]\n","[18 / 20]   Val: Loss = 0.02151, Accuracy = 97.07%: 100%|██████████| 13/13 [00:00<00:00, 58.94it/s]\n","[19 / 20] Train: Loss = 0.01293, Accuracy = 98.78%: 100%|██████████| 572/572 [00:03<00:00, 156.36it/s]\n","[19 / 20]   Val: Loss = 0.02075, Accuracy = 97.10%: 100%|██████████| 13/13 [00:00<00:00, 65.42it/s]\n","[20 / 20] Train: Loss = 0.01233, Accuracy = 98.83%: 100%|██████████| 572/572 [00:03<00:00, 161.23it/s]\n","[20 / 20]   Val: Loss = 0.02108, Accuracy = 97.09%: 100%|██████████| 13/13 [00:00<00:00, 68.65it/s]\n"]}],"source":["model = LSTMTaggerWithPretrainedEmbs(\n","    embeddings=embeddings,\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(model.parameters())\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"]},{"cell_type":"markdown","metadata":{"id":"2Ne_8f24h8kg"},"source":["**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n","\n","Добейтесь качества лучше прошлых моделей."]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HPUuAPGhEGVR","executionInfo":{"status":"ok","timestamp":1682360487461,"user_tz":-420,"elapsed":1331,"user":{"displayName":"Machine","userId":"11630897638309145340"}},"outputId":"a8d3b6d8-f2cc-4c51-8167-2a0a30224c95"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.9717102020699853\n"]}],"source":["accum = 0\n","butch_count = 0\n","for X_test_batch, y_test_batch in iterate_batches((X_test, y_test), 512):\n","    X_batch, y_batch = LongTensor(X_test_batch), LongTensor(y_test_batch)\n","    test_prediction = model(X_batch)\n","    butch_count += 1\n","    right, all = get_accuracy(test_prediction, y_batch)\n","    accum = right / all\n","average = accum / butch_count\n","print(accum)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}